<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="顺风不浪，逆风不怂！形而上学，不行退学！">
<meta property="og:type" content="website">
<meta property="og:title" content="Gsynf | My Blog">
<meta property="og:url" content="https:&#x2F;&#x2F;gsynf.github.io&#x2F;page&#x2F;12&#x2F;index.html">
<meta property="og:site_name" content="Gsynf | My Blog">
<meta property="og:description" content="顺风不浪，逆风不怂！形而上学，不行退学！">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://gsynf.github.io/page/12/"/>





  <title>Gsynf | My Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Gsynf | My Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">曾梦想仗剑天涯，后来学习忙没去</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://gsynf.github.io/2019/05/07/2019-05-07-Mask%20R-CNN%E6%80%BB%E7%BB%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gsynf">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gsynf | My Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/07/2019-05-07-Mask%20R-CNN%E6%80%BB%E7%BB%93/" itemprop="url">Mask R-CNN总结</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-05-07T00:00:00+08:00">
                2019-05-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>原文链接：<a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener">https://arxiv.org/abs/1703.06870</a><br>目前找到了非常好的一位博客：<a href="https://blog.csdn.net/WZZ18191171661/article/details/79453780，" target="_blank" rel="noopener">https://blog.csdn.net/WZZ18191171661/article/details/79453780，</a> 感谢！<br><a href="https://blog.csdn.net/jiongnima/article/details/79094159，" target="_blank" rel="noopener">https://blog.csdn.net/jiongnima/article/details/79094159，</a> 这个也不错。<br>相关知识介绍：<br>R-CNN-<a href="https://www.jianshu.com/p/5056e6143ed5" target="_blank" rel="noopener">https://www.jianshu.com/p/5056e6143ed5</a>;<br>Faster R-CNN-<a href="https://blog.csdn.net/qq_17448289/article/details/52871461" target="_blank" rel="noopener">https://blog.csdn.net/qq_17448289/article/details/52871461</a><br><a href="https://blog.csdn.net/u011974639/article/details/78053203" target="_blank" rel="noopener">https://blog.csdn.net/u011974639/article/details/78053203</a>, 个人感觉这两篇讲的很好。</p>
</blockquote>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><ul>
<li>Mask RCNN可以看做是一个通用实例分割架构。</li>
<li>Mask RCNN以Faster RCNN原型，增加了一个分支用于分割任务。</li>
<li>Mask RCNN比Faster RCNN速度慢一些，达到了5fps。</li>
<li>可用于人的姿态估计等其他任务</li>
</ul>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h1><ul>
<li>实例分割不仅要正确的找到图像中的objects，还要对其精确的分割。所以Instance Segmentation可以看做object dection和semantic segmentation的结合。</li>
<li>Mask RCNN是Faster RCNN的扩展，对于Faster RCNN的每个Proposal Box都要使用FCN进行语义分割，分割任务与定位、分类任务是同时进行的。</li>
<li>引入了RoI Align代替Faster RCNN中的RoI Pooling。因为RoI Pooling并不是按照像素一一对齐的（pixel-to-pixel alignment），也许这对bbox的影响不是很大，但对于mask的精度却有很大影响。使用RoI Align后mask的精度从10%显著提高到50%，第3节将会仔细说明。</li>
<li>引入语义分割分支，实现了mask和class预测的关系的解耦，mask分支只做语义分割，类型预测的任务交给另一个分支。这与原本的FCN网络是不同的，原始的FCN在预测mask时还用同时预测mask所属的种类。</li>
<li>没有使用什么花哨的方法，Mask RCNN就超过了当时所有的state-of-the-art模型。</li>
<li>使用8-GPU的服务器训练了两天。</li>
</ul>
<h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2.Related Work"></a>2.Related Work</h1><ul>
<li>相比于FCIS，FCIS使用全卷机网络，同时预测物体classes、boxes、masks，速度更快，但是对于重叠物体的分割效果不好。</li>
</ul>
<h1 id="3-Mask-R-CNN"><a href="#3-Mask-R-CNN" class="headerlink" title="3.Mask R-CNN"></a>3.Mask R-CNN</h1><ul>
<li>Mask R-CNN基本结构：与Faster RCNN采用了相同的two-state步骤：首先是找出RPN，然后对RPN找到的每个RoI进行分类、定位、并找到binary mask。这与当时其他先找到mask然后在进行分类的网络是不同的。</li>
<li>Mask R-CNN的损失函数：L = L<sub>cls</sub> + L<sub>box</sub> + L<sub>mask</sub></li>
<li>Mask的表现形式(Mask Representation)：因为没有采用全连接层并且使用了RoIAlign，可以实现输出与输入的像素一一对应。</li>
<li>RoIAlign：RoIPool的目的是为了从RPN网络确定的ROI中导出较小的特征图(a small feature map，eg 7x7)，ROI的大小各不相同，但是RoIPool后都变成了7x7大小。RPN网络会提出若干RoI的坐标以[x,y,w,h]表示，然后输入RoI Pooling，输出7x7大小的特征图供分类和定位使用。问题就出在RoI Pooling的输出大小是7x7上，如果RON网络输出的RoI大小是8*8的，那么无法保证输入像素和输出像素是一一对应，首先他们包含的信息量不同（有的是1对1，有的是1对2），其次他们的坐标无法和输入对应起来（1对2的那个RoI输出像素该对应哪个输入像素的坐标？）。这对分类没什么影响，但是对分割却影响很大。RoIAlign的输出坐标使用插值算法得到，不再量化；每个grid中的值也不再使用max，同样使用差值算法。</li>
<li>Network Architecture: 为了表述清晰，有两种分类方法</li>
</ul>
<ol>
<li>使用了不同的backbone：resnet-50，resnet-101，resnext-50，resnext-101；</li>
<li>使用了不同的head Architecture：Faster RCNN使用resnet50时，从CONV4导出特征供RPN使用，这种叫做ResNet-50-C4</li>
<li>作者使用除了使用上述这些结构外，还使用了一种更加高效的backbone——FPN</li>
</ol>
<h2 id="3-1-Implementation-Details"><a href="#3-1-Implementation-Details" class="headerlink" title="3.1.Implementation Details"></a>3.1.Implementation Details</h2><p>使用Fast/Faster相同的超参数，同样适用于Mask RCNN</p>
<ul>
<li>Training:<br>1、与之前相同，当IoU与Ground Truth的IoU大于0.5时才会被认为有效的RoI，L{_{mask}}只把有效RoI计算进去。<br>2、采用image-centric training，图像短边resize到800，每个GPU的mini-batch设置为2，每个图像生成N个RoI，对于C4 backbone的N=64，对于FPN作为backbone的，N=512。作者服务器中使用了8块GPU，所以总的minibatch是16，迭代了160k次，初始lr=0.02，在迭代到120k次时，将lr设定到 lr=0.002，另外学习率的weight_decay=0.0001，momentum = 0.9。如果是resnext，初始lr=0.01,每个GPU的mini-batch是1。<br>3、RPN的anchors有5种scale，3种ratios。为了方便剥离、如果没有特别指出，则RPN网络是单独训练的且不与Mask R-CNN共享权重。但是在本论文中，RPN和Mask R-CNN使用一个backbone，所以他们的权重是共享的。<br>（Ablation Experiments 为了方便研究整个网络中哪个部分其的作用到底有多大，需要把各部分剥离开）</li>
</ul>
<ul>
<li>Inference：<br>在测试时，使用C4 backbone情况下proposal number=300，使用FPN时proposal number=1000。然后在这些proposal上运行bbox预测，接着进行非极大值抑制。mask分支只应用在得分最高的100个proposal上。顺序和train是不同的，但这样做可以提高速度和精度。mask 分支对于每个roi可以预测k个类别，但是我们只要背景和前景两种，所以只用k-th mask，k是根据分类分支得到的类型。然后把k-th mask resize成roi大小，同时使用阈值分割(threshold=0.5)二值化</li>
</ul>
<h1 id="4-Experiments-Instance-Segmentation"><a href="#4-Experiments-Instance-Segmentation" class="headerlink" title="4.Experiments: Instance Segmentation"></a>4.Experiments: Instance Segmentation</h1><h2 id="4-1-Main-Results"><a href="#4-1-Main-Results" class="headerlink" title="4.1.Main Results"></a>4.1.Main Results</h2><p>在下图中可以明显看出，FCIS的分割结果中都会出现一条竖着的线(systematic artifacts)，这线主要出现在物体重的部分，作者认为这是FCIS架构的问题，无法解决的。但是在Mask RCNN中没有出现。<br><img src="https://i.loli.net/2019/04/29/5cc65cc9ecfc3.png" alt="figure6&amp;table2"></p>
<h2 id="4-2-Ablation-Experiments"><a href="#4-2-Ablation-Experiments" class="headerlink" title="4.2. Ablation Experiments"></a>4.2. Ablation Experiments</h2><ul>
<li>Architecture:<br>从table 2a中看出，Mask RCNN随着增加网络的深度、采用更先进的网络，都可以提高效果。注意：并不是所有的网络都是这样。</li>
<li>Multinomial vs. Independent Masks:(mask分支是否进行类别预测)                                                                                    从table 2b中可以看出，使用sigmoid(二分类)和使用softmax(多类别分类)的AP相差很大，证明了分离类别和mask的预测是很有必要的</li>
<li>Class-Specific vs. Class-Agnostic Masks:                                                                                                                            目前使用的mask rcnn都使用class-specific masks，即每个类别都会预测出一个mxm的mask，然后根据类别选取对应的类别的mask。但是使用Class-Agnostic Masks，即分割网络只输出一个mxm的mask，可以取得相似的成绩29.7vs30.3</li>
<li>RoIAlign:                                                                                                                                                                                    tabel 2c证明了RoIAlign的性能</li>
<li>Mask Branch:<br>tabel 2e，FCN比MLP性能更好</li>
</ul>
<h2 id="4-3-Bounding-Box-Detection-Results"><a href="#4-3-Bounding-Box-Detection-Results" class="headerlink" title="4.3.Bounding Box Detection Results"></a>4.3.Bounding Box Detection Results</h2><ul>
<li>Mask RCNN精度高于Faster RCNN</li>
<li>Faster RCNN使用RoI Align的精度更高</li>
<li>Mask RCNN的分割任务得分与定位任务得分相近，说明Mask RCNN已经缩小了这部分差距。</li>
</ul>
<h2 id="4-4-Timing"><a href="#4-4-Timing" class="headerlink" title="4.4.Timing"></a>4.4.Timing</h2><ul>
<li>Inference：195ms一张图片，显卡Nvidia Tesla M40。其实还有速度提升的空间，比如减少proposal的数量等。</li>
<li>Training：ResNet-50-FPN on COCO trainval35k takes 32 hours  in our synchronized 8-GPU implementation (0.72s per 16-image mini-batch)，and 44 hours with ResNet-101-FPN。</li>
</ul>
<h1 id="5-Mask-R-CNN-for-Human-Pose-Estimation"><a href="#5-Mask-R-CNN-for-Human-Pose-Estimation" class="headerlink" title="5. Mask R-CNN for Human Pose Estimation"></a>5. Mask R-CNN for Human Pose Estimation</h1><p>让Mask R-CNN预测k个masks，每个mask对应一个关键点的类型，比如左肩、右肘，可以理解为one-hot形式。</p>
<ul>
<li>使用cross entropy loss，可以鼓励网络只检测一个关键点;</li>
<li>ResNet-FPN结构</li>
<li>训练了90k次，最开始lr=0.02，在迭代60k次时，lr=0.002,80k次时变为0.0002</li>
</ul>
<p><img src="https://i.loli.net/2019/04/29/5cc65f4085801.png" alt="figure7"><br><em>图7.使用Mask R-CNN（ResNet-50-FPN）在COCO测试中的关键点检测结果，以及从相同模型预测的人分割掩码。该模型的关键点AP为63.1，运行速度为5 fps。</em></p>
<p><img src="https://i.loli.net/2019/04/29/5cc6605e29496.png" alt="table4/5/6"></p>
<p>以上。</p>
<p><strong><em>注</em></strong>：转载文章请注明出处，谢谢~</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://gsynf.github.io/2019/04/29/2019-04-29-Mask%20R-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gsynf">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gsynf | My Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/29/2019-04-29-Mask%20R-CNN/" itemprop="url">Mask R-CNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-29T00:00:00+08:00">
                2019-04-29
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>原文链接：<a href="https://arxiv.org/abs/1703.06870" target="_blank" rel="noopener">https://arxiv.org/abs/1703.06870</a><br>Mask R-CNN是ICCV 2017的best paper，彰显了机器学习计算机视觉领域在2017年的最新成果。在机器学习2017年的最新发展中，单任务的网络结构已经逐渐不再引人瞩目，取而代之的是集成，复杂，一石多鸟的多任务网络模型。Mask R-CNN就是典型的代表。本篇大作的一作是何凯明，在该篇论文发表的时候，何凯明已经去了FaceBook。</p>
</blockquote>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p><em>我们提出了一个概念上简单，灵活和通用的对象实例分割框架。我们的方法有效地检测图像中的对象，同时为每个实例生成高质量的分割蒙版。这种称为Mask R-CNN的方法通过添加一个用于预测对象掩码的分支来扩展更快的R-CNN，该分支与现有的用于边界框识别的分支并行。掩码R-CNN训练简单，只增加了一小部分开销，以更快的R-CNN，以5fps运行。此外，Mask R-CNN很容易推广到其他任务，例如允许我们在相同的框架中估计人的姿势。我们在COCO全套挑战的所有三个轨道中展示了最佳结果，包括实例分段，边界盒对象检测和人员关键点检测。Mask R-CNN无需花费大量时间就可胜任所有现有的单一模型作品，包括COCO 2016挑战获胜者。我们希望我们简单有效的方法将成为一个坚实的基线，并有助于缓解未来实例级别识别的研究。代码已在：<a href="https://github.com/" target="_blank" rel="noopener">https://github.com/</a> facebookresearch / Detectron上提供。</em></p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1.Introduction"></a>1.Introduction</h1><p>视觉社区在短时间内迅速改进了对象检测和语义分割结果。在很大程度上，这些进步是由强大的基线系统驱动的，例如分别用于对象检测和语义分割的快速/更快RCNN [12,36]和全卷积网络（FCN）[30]框架。这些方法在概念上是直观的，并且具有灵活性和鲁棒性，以及快速训练和推理时间。我们在这项工作中的目标是为实例分割开发一个相对有利的框架。实例分割具有挑战性，因为它需要正确检测图像中的所有对象，同时也精确地分割每个实例。因此，它将经典的目标检测计算机视觉任务的元素进行了组合，其目标是对各个对象进行分类并使用边界框对每个对象进行本地化，然后进行语义分割，其目的是将每个像素分类为固定的一组类别，而不区分对象实例.1鉴于此，人们可能期望需要一个复杂的方法才能取得好的结果。然而，我们表明，一个令人惊讶的简单，灵活和快速的系统可以超越先前的最新实例分割结果。<br>我们的方法称为Mask R-CNN，可以使R-CNN更快。<br><img src="https://i.loli.net/2019/04/29/5cc657a3425e5.png" alt="figure1"><br><em>图1.用于实例分段的Mask R-CNN框架。</em></p>
<p>[36]通过添加一个分支来预测每个感兴趣区域（RoI）上的分割掩模，并与现有分支进行分类和边界框回归（图1）。掩模分支是应用于每个RoI的小FCN，以像素 - 顶像素方式预测分割掩模。由于R-CNN框架更加快速，面罩R-CNN的实施和训练变得非常简单，这有助于广泛的灵活架构设计。另外，掩码分支只会增加一个小的计算开销，从而实现快速系统和快速实验。<br>原则上，Mask R-CNN是R-CNN的直观扩展，但正确构建掩模分支对于获得好的结果至关重要。最重要的是，更快的RCNN并非针对网络输入和输出之间的像素对像素对齐而设计的。RoIPool [18,12]是参与实例的事实核心操作，为特征提取执行粗略的空间量化，这一点最为明显。为了找到错位，我们提出了一个简单的，无量化的图层，称为RoIAlign，忠实地保留了确切的空间位置。尽管1遵循通用术语，但我们使用对象检测来表示通过边界框而不是掩码进行检测，并使用语义分割来表示每像素分类而不区分实例。但是我们注意到，实例分割既是语义的，也是一种检测形式。<br><img src="https://i.loli.net/2019/04/29/5cc658728ff4e.png" alt="figure2"><br><em>图2.掩盖COCO测试集上的R-CNN结果。这些结果基于ResNet-101 [19]，实现了35.7的掩模AP，并以5 fps运行。面具以彩色显示，还显示了边界框，类别和置信度。</em></p>
<p>一个看似微小的变化，RoIAlign具有很大的影响：它将掩模精度提高了10％到50％，在更严格的本地化指标下显示出更大的收益。其次，我们发现解耦模板和类别预测至关重要：我们独立预测每个类别的二进制掩码，而不需要在类别间进行竞争，并依靠网络的RoI分类分支来预测类别。相比之下，FCNs通常执行每像素多类别分类，结合分割和分类，并基于我们的实验在分割实例方面效果不佳。<br>没有花里胡哨之力，Mask R-CNN超越了COCO实例分割任务中所有先前的最新单模型结果[28]，其中包括来自2016年竞赛冠军的大量工程项目。作为副产品，我们的方法也擅长COCO物体检测任务。在消融实验中，我们评估了多个基本实例，这使我们能够展示其强大性并分析核心因素的影响。<br>我们的模型可以在GPU上以每帧200毫秒的速度运行，并且在单个8 GPU计算机上进行COCO培训需要一到两天。我们相信，快速训练和测试速度，以及框架的灵活性和准确性，将会对实例分割的未来研究起到一定的作用。<br>最后，我们通过COCO关键点数据集上的人体姿态估计任务展示了我们框架的一般性[28]。通过将每个关键点视为一个热门的二进制掩码，只需进行最少的修改Mask R-CNN可用于检测实例特定的姿势。Mask R-CNN超越2016年COCO关键点竞赛的冠军，同时运行速度为5 fps。因此，面膜R-CNN可以更广泛地视为实例级别识别的灵活框架，并且可以很容易地扩展到更复杂的任务。<br>我们已发布代码以促进未来的研究。</p>
<h1 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2.Related Work"></a>2.Related Work</h1><p>R-CNN：基于区域的CNN（R-CNN）方法[13]对边界框对象进行检测是为了关注可管理数量的候选目标区域[42,20]并独立评估卷积网络[25,24]在每个RoI上。R-CNN得到了扩展[18,12]，允许使用RoIPool在功能地图上参与RoI，从而实现更快的速度和更高的准确性。更快的R-CNN [36]通过学习区域建议网络（RPN）的注意机制来推进这一流程。更快速的R-CNN灵活性强，适用于许多后续改进（例如[38,27,21]），并且是几个基准测试中的当前领先框架。<br>实例细分：在RCNN的有效性的推动下，许多实例细分的方法都基于细分提案。早期的方法[13,15,16,9]采用了自下而上的方法[42,2]。DeepMask [33]和以下着作[34,8]学会提出片段候选者，然后由Fast R-CNN进行分类。在这些方法中，分割先于识别，这是缓慢的并且不太准确。同样，戴等人。 [10]提出了一个复杂的多级级联，从包围盒提议中预测段提议，然后进行分类。相反，我们的方法基于面具和类标签的并行预测，它更简单，更灵活。<br>最近，李等人。 [26]将[8]中的段提议系统和[11]中的对象检测系统合并为“完全卷积实例分段”（FCIS）。[8,11,26]中的共同想法是预测一组完全卷积的位置敏感输出通道。这些通道同时处理对象类，框和掩码，使系统更快。但是FCIS在重叠实例上表现出系统性错误并产生虚假边缘（图6），表明它受到分割实例的根本困难的挑战。<br>另一个解决方案家族[23,4,3,29]实例分割是由语义分割的成功驱动的。从每像素分类结果（例如，FCN输出）开始，这些方法试图将相同类别的像素切割成不同的实例。与这些方法的分段第一策略相比，Mask R-CNN基于实例第一策略。我们预计未来将研究更深入的两种战略。</p>
<h1 id="3-Mask-R-CNN"><a href="#3-Mask-R-CNN" class="headerlink" title="3.Mask R-CNN"></a>3.Mask R-CNN</h1><p>掩码R-CNN在概念上是简单的：更快的R-CNN对于每个候选对象具有两个输出，一个类别标签和一个边界框偏移;为此，我们添加一个输出对象掩码的第三个分支。面具R-CNN因此是一个自然而直观的想法。但是额外的掩码输出与类和盒输出不同，需要提取对象的更精细的空间布局。接下来，我们介绍Mask R-CNN的关键元素，包括像素对像素对齐，这是Fast / Faster R-CNN的主要缺失部分。<br>更快的R-CNN：我们首先回顾一下更快的R-CNN探测器[36]。更快的R-CNN由两个阶段组成。第一阶段称为区域提议网络（RPN），提出候选对象边界框。第二阶段本质上是Fast R-CNN [12]，使用每个候选框中的RoIPool提取特征，并执行分类和边界框回归。两个阶段使用的功能可以共享以加快推断速度。我们引用读者[21]对Faster R-CNN和其他框架进行最新，全面的比较。<br>掩码R-CNN：掩码R-CNN采用相同的两阶段过程，具有相同的第一阶段（即RPN）。在第二阶段，与预测类和盒子偏移并行，Mask R-CNN也为每个RoI输出一个二进制掩码。这与大多数最近的系统形成对比，其中分类依赖于掩模预测（例如[33,10,26]）。我们的方法遵循Fast R-CNN [12]的精神，它并行地应用了边界框分类和回归（其原来大大简化了原始R-CNN的多级流水线[13]）。<br>形式上，在训练期间，我们将每个抽样的RoI的多任务丢失定义为L = Lcls + Lbox + Lmask。分类损失Lcls和边界框损失Lbox与[12]中定义的相同。掩码分支对每个RoI都有一个Km<sup>2</sup>维输出，它编码分辨率为m*m的K个二进制掩码，每个K类一个掩码。为此，我们应用每像素S形，并将Lmask定义为平均二叉交叉熵损失。对于与地面实况类别k相关的RoI，Lmask仅在第k个掩模上定义（其他掩模输出不会造成损失）。<br>我们对Lmask的定义允许网络为每个班级生成口罩，而不需要在班级间进行竞争;我们依靠专用分类分支来预测用于选择输出掩码的类别标签。这样可以将掩码和类别预测分开。这与将FCN [30]应用于语义分割时的常见做法不同，后者通常使用每像素softmax和多项叉熵损失。在这种情况下，跨班级的面具竞争;在我们的例子中，每像素S形和二进制丢失，他们不。我们通过实验显示这个公式对于良好的实例分割结果是关键的。<br><img src="https://i.loli.net/2019/04/29/5cc65a2a8366b.png" alt="figure3"></p>
<p>掩码表示法：掩码编码输入对象的空间布局。因此，与通过完全连接（fc）层不可避免地折叠成短输出矢量的类标签或框偏移不同，提取掩模的空间结构可以通过卷积提供的像素到像素对应自然地解决。<br>具体而言，我们使用FCN预测每个RoI的m<em>m掩码[30]。这允许掩码分支中的每个层保持显式m*m对象空间布局，而不将其折叠成缺少空间维度的向量表示。与之前采用fc层进行掩模预测的方法不同[33,34,10]，我们的完全卷积表示需要更少的参数，并且如实验所证明的那样更精确。<br>这种像素到像素的行为要求我们的RoI特征（它们本身是小特征图）能够很好地对齐以忠实地保留显式的每像素空间对应关系。这促使我们开发了以下RoAlign图层，该图层在遮罩预测中发挥关键作用。<br>RoIlign：RoIPool [12]是从每个RoI提取小特征映射（例如7×7）的标准操作。RoIPool首先将浮点数RoI量化为特征映射的离散粒度，然后将这个量化的RoI细分为自身量化的空间仓，最后汇总每个仓所涵盖的特征值（通常通过最大池）。例如，通过计算在连续坐标x上执行量化，其中16是特征映射步长并且是舍入;同样地，当分成分箱（例如，7×7）时执行量化。这些量化引入了RoI和提取的特征之间的错位。虽然这可能不会影响分类，这对于小型翻译很有用，但它对预测像素精确的蒙版有很大的负面影响。<br>为了解决这个问题，我们提出一个RoIlign层，它可以消除RoIPool的严格量化，正确地将提取的特征与输入对齐。我们提出的改变很简单：我们避免任何RoI边界或分区的量化（即，我们使用x/16而不是|x/16|）。我们使用双线性插值[22]来计算每个RoI bin中四个有规律采样位置的输入特征的精确值，并汇总结果（使用最大值或平均值），详细信息请参见图3。我们注意到，只要未执行量化，结果对精确的采样位置不敏感，或者采样了多少个点。<br>正如我们在§4.2中所展示的，RoIAlign带来了巨大的改进。我们也比较了[10]中提出的RoIWarp操作。与RoIlign不同，RoIWarp忽略了对齐问题，并在[10]中将RoI与RoIPool一样量化为RoI。所以即使RoIWarp也采用[22]激励的双线性重采样，它可以像RoIPool一样实验（表2c中的更多细节），证明了对齐的关键作用。<br>网络体系结构：为了演示我们的方法的一般性，我们实例化具有多种体系结构的Mask R-CNN。为了清楚起见，我们区分：（i）用于整个图像上的特征提取的卷积骨干架构，以及（ii）用于边界框识别（分类和回归）的网络头和分别应用于每个RoI的掩模预测。我们用命名网络深度特征来表示骨干架构。我们评估深度为50或101层的ResNet [19]和ResNeXt [45]网络。带ResNets的更快的R-CNN的原始实施。<br>[19]从第四阶段的最后卷积层提取特征，我们称之为C4。例如，ResNet-50的骨干用ResNet-50-C4表示。这是[19,10,21,39]中常用的选择。<br>我们还探索了Lin等人最近提出的另一种更有效的骨干。 [27]，称为特征金字塔网络（FPN）。FPN使用具有横向连接的自顶向下架构从单一比例输入构建网络内特征金字塔。更快的R-CNN和FPN骨干网根据其规模从不同层次的特征金字塔中提取RoI特征，但其他方法与vanilla ResNet类似。使用ResNet-FPN主干进行MaskNRCNN特征提取，可以提高精度和速度。有关FPN的更多详细信息，请参阅[27]。<br>对于网络负责人，我们密切关注以前工作中提出的架构，并在其中添加完全卷积掩码预测分支。具体而言，我们从ResNet [19]和FPN [27]论文中扩展了更快的R-CNN盒头。详细情况如图4所示。ResNet-C4主干上包含ResNet的第5级（即9层’res5’[19]），它是计算密集型的。对于FPN，骨干已经包含res5，因此可以使用更少的滤波器来提高效率。我们注意到我们的面具分支有一个简单的结构。更复杂的设计有提高性能的潜力，但不是这项工作的重点。<br><img src="https://i.loli.net/2019/04/29/5cc65b1069756.png" alt="figure4"><br>*图4.头架构：我们扩展了两个现有的更快的RCNN头[19,27]。左/右面板分别显示来自[19]和[27]的ResNet C4和FPN骨干的头部，其中添加了掩膜分支。数字表示空间分辨率和频道。箭头表示可以从上下文推断的conv，deconv或fc图层（conv会保留空间维度，而deconv会增加它）。所有的转换都是3×3，除了输出转换为1×1，解压缩为2×2和步长2，并且我们在隐藏层中使用了ReLU [31]。左：res5表示ResNet的第五阶段，为了简单起见，我们改变了第一阶段的第一阶段，以步幅1（而不是14×14 /步幅2，如[19]中的7×7阶段）操作。右：“×4”表示一连串四次转换。</em></p>
<h2 id="3-1-Implementation-Details"><a href="#3-1-Implementation-Details" class="headerlink" title="3.1.Implementation Details"></a>3.1.Implementation Details</h2><p>我们在现有的快速/更快的R-CNN工作之后设置超参数[12,36,27]。尽管这些决策是在原始文件中进行对象检测的[12,36,27]，但我们发现我们的实例分割系统对它们是强健的。<br>培训：与Fast R-CNN一样，如果RoI的IoU的地面实况框至少为0.5，则认为是正面的，否则为负面。掩模损失Lmask仅在正向RoI上定义。掩码目标是RoI与其关联的地面实况蒙版之间的交集。<br>我们采用图像中心训练[12]。调整图像的大小以使其比例（较短的边缘）为800像素[27]。每个微型批次每个GPU有2个图像，每个图像具有N个采样的RoI，比例为1：3的正负极[12]。C4骨架的N为64（如[12,36]），FPN为512（如[27]）。我们在8个GPU（有效小批量大小为16）上进行160k次迭代训练，学习率为0.02，在120k迭代时减少10。我们使用0.0001的重量衰减和0.9的动量。使用ResNeXt [45]，我们每个GPU训练1个图像，迭代次数相同，初始学习率为0.01。RPN锚点跨越5个尺度和3个纵横比，见[27]。为了方便消融，除非另有说明，否则RPN将单独进行培训并且不会与Mask R-CNN共享特征。对于本文中的每个条目，RPN和Mask R-CNN具有相同的主干，因此它们可共享。<br>推论：在测试时，C4主干的提案编号为300（如[36]），FPN的提案编号为1000（如[27]）。我们对这些提议运行盒子预测分支，然后是非最大抑制[14]。然后将掩码分支应用于得分最高的100个检测框。虽然这与训练中使用的并行计算不同，但它加快了推理速度并提高了准确性（由于使用了更少，更准确的RoI）。掩模分支可以预测每个RoI的K个掩模，但我们只使用第k个掩模，其中k是分类分支预测的类。然后将m×m浮点数掩码输出调整为RoI大小，并在阈值0.5下进行二进制化。<br><img src="https://i.loli.net/2019/04/29/5cc65b990f59b.png" alt="figure5"><br><em>图5.在COCO测试图像上使用ResNet-101-FPN并以5 fps运行并带有35.7掩模AP（表1）的Mask R-CNN的更多结果。</em></p>
<p><img src="https://i.loli.net/2019/04/29/5cc65bd2acd59.png" alt="table1"><br><em>表1. COCO test-dev上的实例分段掩码AP。跨国公司[10]和FCIS [26]分别是2015年和2016年分类挑战的赢家。没有花里胡哨的，Mask R-CNN胜过了更复杂的FCIS +++，其中包括多尺度训练/测试，水平测试和OHEM [38]。所有条目都是单模型结果。</em></p>
<p>请注意，由于我们仅计算前100个检测框中的掩码，Mask R-CNN为其较快的R-CNN对象（例如典型模型上的约20％）增加了一个小的开销。</p>
<h1 id="4-Experiments-Instance-Segmentation"><a href="#4-Experiments-Instance-Segmentation" class="headerlink" title="4.Experiments: Instance Segmentation"></a>4.Experiments: Instance Segmentation</h1><p>我们对Mask R-CNN进行了彻底的比较，并对COCO数据集进行了全面的消融[28]。我们报告标准的COCO指标，包括AP（平均在IoU阈值上），AP50，AP75和APS，APM，APL（AP在不同尺度上）。除非另有说明，否则AP正在使用掩膜IoU进行评估。和以前的工作[5,27]一样，我们训练使用80k列车图像和val图像的35k子集（trainval35k）的联合，并报告其余5k val图像（微型）上的消融。我们还在测试开发中报告结果[28]。</p>
<h2 id="4-1-Main-Results"><a href="#4-1-Main-Results" class="headerlink" title="4.1.Main Results"></a>4.1.Main Results</h2><p>我们将Mask R-CNN与表1中实例分割中的最新方法进行了比较。我们模型的所有实例都优于先前最先进的模型的基线变体。其中包括MNC [10]和FCIS [26]，分别是2015年和2016年分类挑战的获胜者。ResNet-101-FPN骨干网掩码R-CNN的性能优于FCIS +++ [26]，其中包括多尺度训练/测试，水平流测试和在线硬示例挖掘（OHEM）[38]。虽然超出了本工作的范围，但我们预计许多此类改进将适用于我们的工作。图2和图5中显示了掩膜R-CNN输出。面具R-CNN即使在具有挑战性的条件下也能取得良好效果。在图6中，我们比较了我们的Mask R-CNN基线和FCIS +++ [26]。FCIS +++在重叠的实例中展现出系统性的人为因素，这表明它受到实例分割根本困难的挑战。掩码R-CNN没有显示这样的文物。<br><img src="https://i.loli.net/2019/04/29/5cc65cc9ecfc3.png" alt="figure6&amp;table2"></p>
<h2 id="4-2-Ablation-Experiments"><a href="#4-2-Ablation-Experiments" class="headerlink" title="4.2. Ablation Experiments"></a>4.2. Ablation Experiments</h2><p>我们运行一些消融来分析Mask R-CNN。结果显示在表2中并在下面详细讨论。<br>架构：表2a显示了具有各种骨架的Mask R-CNN。它受益于更深的网络（50对101）和先进的设计，包括FPN和ResNeXt。我们注意到并非所有框架都自动从更深或更高级的网络中获益（参见[21]中的基准测试）。<br>多项式与独立式掩码：掩码R-CNN分离掩码和类别预测：由于现有的分支预测类别标签，因此我们为每个类别生成一个掩码，而不会在类别间进行竞争（按像素S形和二进制丢失）。在表2b中，我们将其与使用每像素softmax和多项损失（如FCN [30]中常用的）进行比较。这种替代方案将掩模和类别预测的任务相结合，并导致掩模AP（5.5分）的严重损失。这表明一旦实例被整体分类（通过盒子分支），预测二进制掩码就足够了，而不用考虑类别，这使得模型更易于训练。<br>Class-Speci fi c与Class-Agnostic Masks：我们的默认实例化预测了类特定的掩码，即一个m<em>m每个班级的面具。有趣的是，具有分类掩码的掩码R-CNN（即预测单个m*m输出而不管类别）几乎同样有效：它具有29.7掩码AP，而对于ResNet-50-C4上的类别特定对应字符，掩码AP为30.3。这进一步突出了我们的方法中的分工，这种分工在很大程度上将分类和分割分开。<br>Roialign：我们建议的RoIlign层的评估如表2c所示。在这个实验中，我们使用了跨度为16的ResNet50-C4主干。RoIAlign比RoIPool提高了约3个点，其中很大的收益来自高IoU（AP75）。RoIlign对最大/平均水池不敏感;我们在本文的其余部分使用平均值。另外，我们与在MNC [10]中提出的RoIWarp进行比较，该方法也采用双线性采样。正如§3所讨论的那样，RoIWarp仍然量化了RoI，失去了与输入的一致性。从表2c可以看出，RoIWarp的表现与RoIPool相当，比RoIAlign差很多。这突出表明正确的对齐是关键。<br>我们还用一个ResNet-50-C5骨干来评估RoIlign，这个骨干有32个像素的更大步幅。我们使用与图4（右）相同的头，因为res5头不适用。表2d显示RoIAlign提高了掩模AP的7.3点，掩盖AP75 10.5点（相对提高50％）。此外，我们注意到使用RoIAlign，使用步幅-32 C5功能（30.9 AP）比使用步幅-16 C4功能（30.3 AP，表2c）更准确。RoIAlign在很大程度上解决了使用大步功能进行检测和分割的长期挑战。最后，与FPN一起使用时，RoIAlign显示1.5掩模AP和0.5盒AP的增益，FPN具有更精细的多级步幅。对于需要精细对齐的关键点检测，RoIAlign即使使用FPN也显示出较大的增益（表6）。<br><img src="https://i.loli.net/2019/04/29/5cc65e0ebda46.png" alt="table3"><br>*遮罩分支：分割是一个像素到像素的任务，我们通过使用FCN来利用遮罩的空间布局。在表2e中，我们使用ResNet-50-FPN主干比较了多层感知器（MLP）和FCN。使用FCN可以提供2.1 Mbps的AP掩码。我们注意到，我们选择了这个骨干，这样FCN头部的conv层没有经过预先训练，与MLP进行公平比较。</em></p>
<h2 id="4-3-Bounding-Box-Detection-Results"><a href="#4-3-Bounding-Box-Detection-Results" class="headerlink" title="4.3.Bounding Box Detection Results"></a>4.3.Bounding Box Detection Results</h2><p>我们将Mask R-CNN与表3中的最新COCO包围盒对象检测进行比较。对于这个结果，即使训练完整的Mask R-CNN模型，只有分类和框输出用于推理（掩码输出被忽略）。使用ResNet-101FPN的面罩R-CNN优于以前所有先进模型的基础变体，其中包括COMI 2016检测挑战赛获胜者GRMI [21]的单模型变体。使用ResNeXt-101-FPN，Mask R-CNN进一步改进了结果，与[39]（使用Inception-ResNet-v2-TDM）的最佳单一模型条目相比，框AP的余量为3.0分。<br>作为进一步的比较，我们训练了一个版本的掩模R-CNN，但没有掩模分支，表3中的“Faster R-CNN，RoIlign”表示。由于RoIlign的原因，该模型的性能比[27]中介绍的模型要好。另一方面，比面具R-CNN低0.9个盒子AP。因此掩模R-CNN在盒子检测上的差距仅仅是由于多任务训练的好处。<br>最后，我们注意到Mask R-CNN在其掩模和盒AP之间获得了一个小间隙：例如，在37.1（掩模，表1）和39.8（框3）之间的2.7个点。这表明我们的方法在很大程度上缩小了对象检测与更具挑战性的实例分割任务之间的差距。</p>
<h2 id="4-4-Timing"><a href="#4-4-Timing" class="headerlink" title="4.4.Timing"></a>4.4.Timing</h2><p>推论：我们训练了一个ResNet-101-FPN模型，该模型在R-CNN更快的四步训练之后训练RPN和Mask R-CNN阶段之间的特征[36]。Nvidia Tesla M40 GPU（加上15ms CPU时间，将输出调整为原始分辨率）时，该模型以195ms的速度运行，并实现与非共享模式相同的掩模AP。我们还报告说ResNet-101-C4变体需要400毫秒，因为它有一个较重的盒子头（图4），所以我们不建议在实践中使用C4变体。<br>尽管掩模R-CNN速度很快，但我们注意到我们的设计并未针对速度进行优化，并且可以实现更好的速度/精度折衷[21]，例如，通过改变图像尺寸和提案编号，这超出了本白皮书的范围。<br>训练：面具R-CNN训练也很快。在COCO trainval35k上使用ResNet-50-FPN进行培训的同步8 GPU实现需要32小时（每16图像微型批次0.72s），使用ResNet-101-FPN需要44小时。实际上，快速原型设计可以在不到一天的时间内在火车上进行训练时完成。我们希望这种快速培训能够消除该领域的一个主要障碍，并鼓励更多的人对这个具有挑战性的话题进行研究。</p>
<h1 id="5-Mask-R-CNN-for-Human-Pose-Estimation"><a href="#5-Mask-R-CNN-for-Human-Pose-Estimation" class="headerlink" title="5. Mask R-CNN for Human Pose Estimation"></a>5. Mask R-CNN for Human Pose Estimation</h1><p>我们的框架可以很容易地扩展到人体姿态估计。我们将一个关键点的位置建模为一个单独的热掩模，并采用掩模R-CNN预测K个掩模，每个K个关键点类型（例如左肩，右肘）各一个。这项任务有助于展示Mask R-CNN的灵活性。我们注意到，我们的系统利用了人类姿态的最小领域知识，因为实验主要是为了展示Mask R-CNN框架的一般性。我们期望领域知识（例如，建模结构[6]）将与我们简单的方法相辅相成。<br>实施细节：对关键点进行调整时，我们对细分系统进行细微修改。对于实例的每个K关键点，训练目标是一个热点二进制掩码，其中只有一个像素标记为前景。在训练过程中，对于每个可见的地面真值关键点，我们将 -way softmax输出的交叉熵损失最小化（鼓励[6]是2016年竞赛获胜者，使用多尺度测试，CPM后处理[使用两种模型（Inception-ResNet-1）对G-RMI进行COCO加MPII [1]（25k图像）的训练，并用目标检测器进行滤波，累加约5个点（在个人通信中加以澄清） v2用于边界框检测，ResNet-101用于关键点）。<br><img src="https://i.loli.net/2019/04/29/5cc65f4085801.png" alt="figure7"><br><em>图7.使用Mask R-CNN（ResNet-50-FPN）在COCO测试中的关键点检测结果，以及从相同模型预测的人分割掩码。该模型的关键点AP为63.1，运行速度为5 fps。</em></p>
<p>单点待检测）。我们注意到，与实例分割一样，K关键点仍然是独立处理的。我们采用ResNet-FPN变体，关键点头结构与图4（右）相似。关键点头由8个3×3 512-d的conv层组成，其后是去卷积层和2倍双线性放大，产生56×56的输出分辨率。我们发现对于关键点级别的定位精度需要相对较高的分辨率输出（与掩模相比）。<br>模型在所有包含注释关键点的COCO trainval35k图像上进行训练。为减少过度训练，由于训练集较小，我们使用从[640,800]像素中随机采样的图像比例进行训练;推断是在800像素的单一尺度上进行的。我们训练90k迭代，从0.02的学习率开始，在60k和80k迭代时将其减少10。我们使用边界框NMS，阈值为0.5。其他细节与§3.1中的相同。<br>主要结果和消融：我们评估人员关键点AP（APkp）并尝试使用ResNet-50-FPN主干;附录中将研究更多骨干。表4显示我们的结果（62.7 APkp）比使用多级处理管道的COCO 2016关键点检测获胜者[6]高0.9个点（见表4的标题）。我们的方法相当简单快捷。<br>更重要的是，我们有一个统一的模型，可以在5 fps下运行时同时预测盒子，分段和关键点。添加段分支（针对人员类别）将test-dev上的APkp值提高到63.1（表4）。表5中更多关于微型多任务学习的消除。将掩码分支添加到仅包装盒（即更快的R-CNN）或仅有关键点的版本可以持续改进这些任务。但是，添加关键点分支会略微减少盒/掩码AP，这表明虽然多任务训练可以实现关键点检测，但它不会帮助其他任务。不过，联合学习所有三项任务可以使统一系统同时有效地预测所有输出（图7）。我们还调查RoIAlign对关键点检测的影响（表6）。尽管ResNet-50-FPN骨干网有很大的进展（例如，在嵌套层面上有4个像素），但RoIAlign仍然显示出比RoIPool有显着的提高，APkp增加4.4点。这是因为关键点检测对定位精度更敏感。这再次表明，对齐对像素级本地化至关重要，包括掩码和关键点。<br><img src="https://i.loli.net/2019/04/29/5cc6605e29496.png" alt="table4/5/6"></p>
<p>以上。</p>
<p><strong><em>注</em></strong>：转载文章请注明出处，谢谢~</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://gsynf.github.io/2019/04/26/2019-04-26-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84_8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gsynf">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gsynf | My Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/26/2019-04-26-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84_8/" itemprop="url">数据结构_8</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-26T00:00:00+08:00">
                2019-04-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>学习过程主要依照中国MOOC<a href="https://www.icourse163.org/learn/ZJU-93001?tid=1003997005#/learn/announce" target="_blank" rel="noopener">课程</a>，感谢MOOC，感谢浙大授课大佬。<br>这里只讨论内部排序，即默认内存空间足够大，可以存放下所有需要排序的数据。</p>
</blockquote>
<h1 id="简单排序（冒泡、插入）"><a href="#简单排序（冒泡、插入）" class="headerlink" title="简单排序（冒泡、插入）#"></a>简单排序（冒泡、插入）#</h1><h2 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h2><p>从上到下比较两个相邻的泡泡，小在上，大在下则不动，否则交换顺序。这为第一趟冒泡，保证将最大的元素放到最下边，然后重复冒泡，直到所有元素均排好序。<br>最好情况：顺序T=O(N)<br>最坏情况：倒序T=O(N<sup>2</sup>)</p>
<h2 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h2><p>类比于打牌时抓牌的过程。<br>最好情况：顺序T=O(N)<br>最坏情况：倒序T=O(N<sup>2</sup>)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">void InsertionSort( ElementType A[], int N )</span><br><span class="line">&#123; /* 插入排序 */</span><br><span class="line">     int P, i;</span><br><span class="line">     ElementType Tmp;</span><br><span class="line">      </span><br><span class="line">     for ( P=1; P&lt;N; P++ ) &#123;</span><br><span class="line">         Tmp = A[P]; /* 取出未排序序列中的第一个元素*/</span><br><span class="line">         for ( i=P; i&gt;0 &amp;&amp; A[i-1]&gt;Tmp; i-- )</span><br><span class="line">             A[i] = A[i-1]; /*依次与已排序序列中元素比较并右移*/</span><br><span class="line">         A[i] = Tmp; /* 放进合适的位置 */</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="时间复杂度下界"><a href="#时间复杂度下界" class="headerlink" title="时间复杂度下界"></a>时间复杂度下界</h2><p>对于下标i&lt;j，如果A[i]&gt;A[j]，则称（i,j）是一对逆序对。<br>冒泡排序和插入排序中需要交换的次数即逆序对数，也就是每次交换消除一个逆序对。</p>
<h1 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h1><p><img src="https://i.loli.net/2019/04/26/5cc2bed0950e0.png" alt="希尔排序"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">void ShellSort( ElementType A[], int N )</span><br><span class="line">&#123; /* 希尔排序 - 用Sedgewick增量序列 */</span><br><span class="line">     int Si, D, P, i;</span><br><span class="line">     ElementType Tmp;</span><br><span class="line">     /* 这里只列出一小部分增量 */</span><br><span class="line">     int Sedgewick[] = &#123;929, 505, 209, 109, 41, 19, 5, 1, 0&#125;;</span><br><span class="line">      </span><br><span class="line">     for ( Si=0; Sedgewick[Si]&gt;=N; Si++ ) </span><br><span class="line">         ; /* 初始的增量Sedgewick[Si]不能超过待排序列长度 */</span><br><span class="line"> </span><br><span class="line">     for ( D=Sedgewick[Si]; D&gt;0; D=Sedgewick[++Si] )</span><br><span class="line">         for ( P=D; P&lt;N; P++ ) &#123; /* 插入排序*/</span><br><span class="line">             Tmp = A[P];</span><br><span class="line">             for ( i=P; i&gt;=D &amp;&amp; A[i-D]&gt;Tmp; i-=D )</span><br><span class="line">                 A[i] = A[i-D];</span><br><span class="line">             A[i] = Tmp;</span><br><span class="line">         &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h1><h2 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h2><p>在i从0到N的循环里，从A[i]到A[i-1]中找到最小元，并将其位置赋给MinPostion，将未排序部分的最小元换到有序部分的最后位置，即交换A[i]和A[MinPostion]。</p>
<h2 id="堆排序-1"><a href="#堆排序-1" class="headerlink" title="堆排序"></a>堆排序</h2><p>将找最小元用最小堆来解决。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">void Swap( ElementType *a, ElementType *b )</span><br><span class="line">&#123;</span><br><span class="line">     ElementType t = *a; *a = *b; *b = t;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line">void PercDown( ElementType A[], int p, int N )</span><br><span class="line">&#123; /* 改编代码4.24的PercDown( MaxHeap H, int p )    */</span><br><span class="line">  /* 将N个元素的数组中以A[p]为根的子堆调整为最大堆 */</span><br><span class="line">    int Parent, Child;</span><br><span class="line">    ElementType X;</span><br><span class="line"> </span><br><span class="line">    X = A[p]; /* 取出根结点存放的值 */</span><br><span class="line">    for( Parent=p; (Parent*2+1)&lt;N; Parent=Child ) &#123;</span><br><span class="line">        Child = Parent * 2 + 1;</span><br><span class="line">        if( (Child!=N-1) &amp;&amp; (A[Child]&lt;A[Child+1]) )</span><br><span class="line">            Child++;  /* Child指向左右子结点的较大者 */</span><br><span class="line">        if( X &gt;= A[Child] ) break; /* 找到了合适位置 */</span><br><span class="line">        else  /* 下滤X */</span><br><span class="line">            A[Parent] = A[Child];</span><br><span class="line">    &#125;</span><br><span class="line">    A[Parent] = X;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">void HeapSort( ElementType A[], int N ) </span><br><span class="line">&#123; /* 堆排序 */</span><br><span class="line">     int i;</span><br><span class="line">       </span><br><span class="line">     for ( i=N/2-1; i&gt;=0; i-- )/* 建立最大堆 */</span><br><span class="line">         PercDown( A, i, N );</span><br><span class="line">      </span><br><span class="line">     for ( i=N-1; i&gt;0; i-- ) &#123;</span><br><span class="line">         /* 删除最大堆顶 */</span><br><span class="line">         Swap( &amp;A[0], &amp;A[i] ); /* 见代码7.1 */</span><br><span class="line">         PercDown( A, 0, i );</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><p>核心：有序子列的归并</p>
<h2 id="递归算法"><a href="#递归算法" class="headerlink" title="递归算法"></a>递归算法</h2><p>分而治之，T(N)=O(NlogN)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">/* 归并排序 - 递归实现 */</span><br><span class="line"> </span><br><span class="line">/* L = 左边起始位置, R = 右边起始位置, RightEnd = 右边终点位置*/</span><br><span class="line">void Merge( ElementType A[], ElementType TmpA[], int L, int R, int RightEnd )</span><br><span class="line">&#123; /* 将有序的A[L]~A[R-1]和A[R]~A[RightEnd]归并成一个有序序列 */</span><br><span class="line">     int LeftEnd, NumElements, Tmp;</span><br><span class="line">     int i;</span><br><span class="line">      </span><br><span class="line">     LeftEnd = R - 1; /* 左边终点位置 */</span><br><span class="line">     Tmp = L;         /* 有序序列的起始位置 */</span><br><span class="line">     NumElements = RightEnd - L + 1;</span><br><span class="line">      </span><br><span class="line">     while( L &lt;= LeftEnd &amp;&amp; R &lt;= RightEnd ) &#123;</span><br><span class="line">         if ( A[L] &lt;= A[R] )</span><br><span class="line">             TmpA[Tmp++] = A[L++]; /* 将左边元素复制到TmpA */</span><br><span class="line">         else</span><br><span class="line">             TmpA[Tmp++] = A[R++]; /* 将右边元素复制到TmpA */</span><br><span class="line">     &#125;</span><br><span class="line"> </span><br><span class="line">     while( L &lt;= LeftEnd )</span><br><span class="line">         TmpA[Tmp++] = A[L++]; /* 直接复制左边剩下的 */</span><br><span class="line">     while( R &lt;= RightEnd )</span><br><span class="line">         TmpA[Tmp++] = A[R++]; /* 直接复制右边剩下的 */</span><br><span class="line">          </span><br><span class="line">     for( i = 0; i &lt; NumElements; i++, RightEnd -- )</span><br><span class="line">         A[RightEnd] = TmpA[RightEnd]; /* 将有序的TmpA[]复制回A[] */</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">void Msort( ElementType A[], ElementType TmpA[], int L, int RightEnd )</span><br><span class="line">&#123; /* 核心递归排序函数 */ </span><br><span class="line">     int Center;</span><br><span class="line">      </span><br><span class="line">     if ( L &lt; RightEnd ) &#123;</span><br><span class="line">          Center = (L+RightEnd) / 2;</span><br><span class="line">          Msort( A, TmpA, L, Center );              /* 递归解决左边 */ </span><br><span class="line">          Msort( A, TmpA, Center+1, RightEnd );     /* 递归解决右边 */  </span><br><span class="line">          Merge( A, TmpA, L, Center+1, RightEnd );  /* 合并两段有序序列 */ </span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">void MergeSort( ElementType A[], int N )</span><br><span class="line">&#123; /* 归并排序 */</span><br><span class="line">     ElementType *TmpA;</span><br><span class="line">     TmpA = (ElementType *)malloc(N*sizeof(ElementType));</span><br><span class="line">      </span><br><span class="line">     if ( TmpA != NULL ) &#123;</span><br><span class="line">          Msort( A, TmpA, 0, N-1 );</span><br><span class="line">          free( TmpA );</span><br><span class="line">     &#125;</span><br><span class="line">     else printf( &quot;空间不足&quot; );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="非递归算法"><a href="#非递归算法" class="headerlink" title="非递归算法"></a>非递归算法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">/* 归并排序 - 循环实现 */</span><br><span class="line">/* 这里Merge函数在递归版本中给出 */</span><br><span class="line"> </span><br><span class="line">/* length = 当前有序子列的长度*/</span><br><span class="line">void Merge_pass( ElementType A[], ElementType TmpA[], int N, int length )</span><br><span class="line">&#123; /* 两两归并相邻有序子列 */</span><br><span class="line">     int i, j;</span><br><span class="line">       </span><br><span class="line">     for ( i=0; i &lt;= N-2*length; i += 2*length )</span><br><span class="line">         Merge( A, TmpA, i, i+length, i+2*length-1 );</span><br><span class="line">     if ( i+length &lt; N ) /* 归并最后2个子列*/</span><br><span class="line">         Merge( A, TmpA, i, i+length, N-1);</span><br><span class="line">     else /* 最后只剩1个子列*/</span><br><span class="line">         for ( j = i; j &lt; N; j++ ) TmpA[j] = A[j];</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">void Merge_Sort( ElementType A[], int N )</span><br><span class="line">&#123; </span><br><span class="line">     int length; </span><br><span class="line">     ElementType *TmpA;</span><br><span class="line">      </span><br><span class="line">     length = 1; /* 初始化子序列长度*/</span><br><span class="line">     TmpA = malloc( N * sizeof( ElementType ) );</span><br><span class="line">     if ( TmpA != NULL ) &#123;</span><br><span class="line">          while( length &lt; N ) &#123;</span><br><span class="line">              Merge_pass( A, TmpA, N, length );</span><br><span class="line">              length *= 2;</span><br><span class="line">              Merge_pass( TmpA, A, N, length );</span><br><span class="line">              length *= 2;</span><br><span class="line">          &#125;</span><br><span class="line">          free( TmpA );</span><br><span class="line">     &#125;</span><br><span class="line">     else printf( &quot;空间不足&quot; );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>以上。</p>
<p><strong><em>注</em></strong>：转载文章请注明出处，谢谢~</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://gsynf.github.io/2019/04/25/2019-04-25-%E4%B8%AD%E5%85%B3%E6%9D%91%E7%A7%91%E5%AD%A6%E5%9F%8E%E7%9A%84%E5%85%B4%E8%B5%B7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gsynf">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gsynf | My Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/25/2019-04-25-%E4%B8%AD%E5%85%B3%E6%9D%91%E7%A7%91%E5%AD%A6%E5%9F%8E%E7%9A%84%E5%85%B4%E8%B5%B7/" itemprop="url">中关村科学城的兴起(1953-1966)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-25T00:00:00+08:00">
                2019-04-25
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>《中关村科学城的兴起(1953-1966)》由胡亚东/郑哲敏/严陆光等口述/杨小林访问整理，湖南教育出版社出版，是20世纪中国科学口述史中其中一部，在此感谢！<br>《中关村科学城的兴起(1953-1966)》选择亲历中国20世纪科学技术发展史的中国著名科学家作为主要访谈对象，本求真之原则，记录其亲历亲闻的史实，并按大致统一的编例整理成书稿。</p>
</blockquote>
<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>本书有意只说1953一1966年这一段，涉及中关村的前史很少，涉及“文革”以后的文字也不多。受访者们，从当年的老乡长到当年的小学生，都曾经是中关衬里的“村民”，是中关村历史变迁约见证人。看访问整理者的编排，书中大体上是循着历史变迁的顺序，讲述一座座科研大楼，一个个研究所，是何时和怎样在这块土地上出现的。其中也讲述了在这里工作和栖居过那些著名的科学家，还捎带着提及与人们日常生活息息相关的基础生活设施的建设，但重点不在系统叙述这里发生过的科研活动和作出的科学贡献。总起来说，是通过亲历者的回忆，让人们认识到科学城中建筑物的布局、研究所的兴革和社区的变迁，以此来展现这座“城“的发展轨迹。</p>
<h1 id="第一篇-村与城"><a href="#第一篇-村与城" class="headerlink" title="第一篇 村与城"></a>第一篇 村与城</h1><h2 id="1-老乡长话中关"><a href="#1-老乡长话中关" class="headerlink" title="1.老乡长话中关"></a>1.老乡长话中关</h2><p>受访人：邓启祥，1954年担任保福寺乡乡长，1955年在中科院化学所工作。<br>主要回顾了保福寺附近区域当年的一些行政、地理情况。</p>
<h2 id="2-蓝图中的科学宫和科学城"><a href="#2-蓝图中的科学宫和科学城" class="headerlink" title="2.蓝图中的科学宫和科学城"></a>2.蓝图中的科学宫和科学城</h2><p>受访人：姜虎文，1954年调入中科院。<br>主要阐述了中科院的选址规划。</p>
<h1 id="第二篇-早期奠基"><a href="#第二篇-早期奠基" class="headerlink" title="第二篇 早期奠基"></a>第二篇 早期奠基</h1><h2 id="3-入住中关村的科学院第一人"><a href="#3-入住中关村的科学院第一人" class="headerlink" title="3.入住中关村的科学院第一人"></a>3.入住中关村的科学院第一人</h2><p>受访人：丘宝剑，中国科学院地理研究所研究员。<br>调入《中华地理志》编辑部，编辑部刚成立时没有地方办公，后来在西郊给社科四所（社会所，近代史所，考古所，语言所）造的房子建好，就搬过去。此地原本叫“中官屯”，编辑部调来一个老文书，负责对外联系，是上海人，听不太懂北京话，问周围老百姓，听成了“中关村”，打印了一批信封、信纸，当时搞“三反”，怕落下“反浪费”罪名，就没改，后来陆续搬来其他所也就都跟着叫了。<br>关于“中官”：有说指太监，有说指中小官员，皇帝在圆明园办公，大员不敢住太远，在附近造房子，剩下的中小官员就在此等着召见，搭个房子之类的。</p>
<h2 id="4-原子能楼"><a href="#4-原子能楼" class="headerlink" title="4.原子能楼"></a>4.原子能楼</h2><p>受访人：叶铭汉，中国工程院院士。<br>清华毕业后在中国科学院近代物理所参加工作，53年改名为物理所，58年改称“原子能研究所”。在中关村建大楼52年开始，53年底54年陆续搬了进来。</p>
<h2 id="5-地球物理研究所"><a href="#5-地球物理研究所" class="headerlink" title="5.地球物理研究所"></a>5.地球物理研究所</h2><p>受访人：朱岗崑，中国科学院地球物理研究所研究员。<br>原为中央研究院气象研究所，气象所在1950年改名为地球物理研究所，所长赵九章，1954年下半年大楼盖好，本部从南京搬来。<br>受访人：吴智诚，曾任中国科学院空间物理研究所党委书记。<br>赵九章先生从事气象、地震、海浪，58年之后主要负责了人造卫星，成立“581”领导小组。<br>空间中心的前身大部分是空间物理所，许多学科骨干都是赵九章带出来的。1997年，42位院士联名为赵九章树立铜像，目前在空间中心大厅内。</p>
<h2 id="6-化学研究所"><a href="#6-化学研究所" class="headerlink" title="6.化学研究所"></a>6.化学研究所</h2><h2 id="7-生物楼：昆虫研究所与动物研究所"><a href="#7-生物楼：昆虫研究所与动物研究所" class="headerlink" title="7.生物楼：昆虫研究所与动物研究所"></a>7.生物楼：昆虫研究所与动物研究所</h2><h2 id="8-力学研究所"><a href="#8-力学研究所" class="headerlink" title="8.力学研究所"></a>8.力学研究所</h2><h1 id="第三篇-“火车头”时代"><a href="#第三篇-“火车头”时代" class="headerlink" title="第三篇 “火车头”时代"></a>第三篇 “火车头”时代</h1><h2 id="9-数学研究所与计算技术研究所"><a href="#9-数学研究所与计算技术研究所" class="headerlink" title="9.数学研究所与计算技术研究所"></a>9.数学研究所与计算技术研究所</h2><p>受访人：许孔时，曾任计算技术研究所副所长，软件研究所所长。<br>数学所筹备处是1950年6月成立的，1952年数学所正式成立，所址在清华园内。1953年数学所成立了一个计算组，1956年在这个组的基础上成立了计算技术研究所，计算所正式成立是1959年，1965年又成立了计算所二部，66年分了出去，成立了微电子学研究所，1985年又有一部分调出，成立了软件所。<br>科学院的头一台就是1958年的103机，苏联援助中国的第一台计算机的资料叫M3，电子管，每秒运算8次，中国人真是聪明，拿过图纸，稍微把电路改进、设计一下，每秒就200次了，这就是103机。</p>
<h2 id="10-化工冶金研究所"><a href="#10-化工冶金研究所" class="headerlink" title="10.化工冶金研究所"></a>10.化工冶金研究所</h2><h2 id="11-电子学研究所"><a href="#11-电子学研究所" class="headerlink" title="11.电子学研究所"></a>11.电子学研究所</h2><h2 id="12-声学研究所"><a href="#12-声学研究所" class="headerlink" title="12.声学研究所"></a>12.声学研究所</h2><h2 id="13-生物物理研究所"><a href="#13-生物物理研究所" class="headerlink" title="13.生物物理研究所"></a>13.生物物理研究所</h2><h2 id="14-微生物研究所"><a href="#14-微生物研究所" class="headerlink" title="14.微生物研究所"></a>14.微生物研究所</h2><h2 id="15-生物物理研究所"><a href="#15-生物物理研究所" class="headerlink" title="15.生物物理研究所"></a>15.生物物理研究所</h2><h2 id="16-自动化研究所"><a href="#16-自动化研究所" class="headerlink" title="16.自动化研究所"></a>16.自动化研究所</h2><h2 id="17-物理研究所"><a href="#17-物理研究所" class="headerlink" title="17.物理研究所"></a>17.物理研究所</h2><h2 id="18-电工研究所"><a href="#18-电工研究所" class="headerlink" title="18.电工研究所"></a>18.电工研究所</h2><h1 id="第四篇-社区与“特楼”"><a href="#第四篇-社区与“特楼”" class="headerlink" title="第四篇 社区与“特楼”"></a>第四篇 社区与“特楼”</h1><h2 id="19-回忆早年的中关村"><a href="#19-回忆早年的中关村" class="headerlink" title="19.回忆早年的中关村"></a>19.回忆早年的中关村</h2><p>受访人：李佩，曾任中科院西郊办公室第一任副主任，中国科学院研究生院英语系主任。<br>当时西郊办公室，都是一些公共事务，管的时期很多。比如请派出所到中关村办公，建粮店，半合作社，建中关村医院等。<br>这一代人，已经走了不少了。活着的也都在八九十岁。我们人与人之间有深厚的感情，对这块地儿也有深厚的感情。住事历历在目，这块地儿住过这么一些人，那么多年发生了那么多的事，若能放到一起，可能够装一个博物馆的。</p>
<h2 id="20-早年中关村的一些服务设施"><a href="#20-早年中关村的一些服务设施" class="headerlink" title="20.早年中关村的一些服务设施"></a>20.早年中关村的一些服务设施</h2><h2 id="21-“特楼”往事"><a href="#21-“特楼”往事" class="headerlink" title="21.“特楼”往事"></a>21.“特楼”往事</h2><p>以上。</p>
<p><strong><em>注</em></strong>：转载文章请注明出处，谢谢~</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://gsynf.github.io/2019/04/23/2019-04-23-Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%B1%95%E7%A4%BA_1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Gsynf">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Gsynf | My Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/04/23/2019-04-23-Python%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%B1%95%E7%A4%BA_1/" itemprop="url">Python数据分析与展示_1</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-04-23T00:00:00+08:00">
                2019-04-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>学习过程主要依照中国MOOC<a href="https://www.icourse163.org/learn/BIT-1001870002?tid=1206192225#/learn/announce" target="_blank" rel="noopener">课程</a>，感谢MOOC，感谢北理授课大佬。</p>
</blockquote>
<h1 id="单元1：NumPy库入门"><a href="#单元1：NumPy库入门" class="headerlink" title="单元1：NumPy库入门"></a>单元1：NumPy库入门</h1><p>数据维度的Python表示：</p>
<ul>
<li>一维数据：列表和集合(无序)类型</li>
<li>多维数据：多维列表类型</li>
<li>高维数据：字典类型或数据表示格式（json,xml.yaml）</li>
</ul>
<p>NumPy是一个开源的Python科学计算基础库。</p>
<ul>
<li>一个强大的N维数组对象 ndarray</li>
<li>广播功能函数</li>
<li>整合C/C++/Fortran代码的工具</li>
<li>线性代数、傅里叶变换、随机生成树等功能</li>
</ul>
<p>NumPy是SciPy、Pandas等数据处理或科学计算库的基础。</p>
<p><strong>引用：</strong> import numpy as np(建议使用上述约定的别名)</p>
<p><strong>ndarray:</strong> 是一个多维数组类型，由两部分构成：1）实际的数据；2）描述这些数据的元数据，如数据维度、数据类型等。ndarray数组一般要求所有元素类型相同，数组下标从0开始。</p>
<p>轴（axis）:保存数据的维度<br>秩（rank）:轴的数量</p>
<ol>
<li>创建</li>
</ol>
<ul>
<li><p>从Python中的列表、元祖等类型创建ndarray数组；</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 使用NumPy中函数创建ndarray数组；</span><br></pre></td></tr></table></figure>
<p>np.arange(n)：类似range()函数；<br>np.ones(shape):根据shape生产一个全1数组；<br>np.zeros(shape):根据shape生产一个全0数组；<br>np.full(shape,val):根据shape生产一个数组，每个元素值都是val；<br>np.eye(n):创建一个n*n的单位矩阵，对角线为1，其余全为0；<br>np.linspace():根据起止数据等间距的填充数据，形成数组；<br>np.concatenate():将两个或多个数组合并成一个新的数组；</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">- 从字节流中创建ndarray数组；</span><br><span class="line">- 从文件中读取特定格式，创建ndarray数组；</span><br><span class="line"></span><br><span class="line">2. 维度变换</span><br><span class="line">.reshape(shape):不改变数组元素，返回一个shape形状的数组，原数组不变；</span><br><span class="line">.resize(shape):同上，但修改原数组；</span><br><span class="line">.swapaxes(ax1,ax2):将数组n个维度中两个维度进行调换；</span><br><span class="line">.flatten():对数组进行降维，返回折叠后的一维数组，原数组不变；</span><br><span class="line">3. 类型转换</span><br><span class="line">.astype(new_type):数组的类型转换</span><br><span class="line">4. 数组转为列表</span><br><span class="line">.tolist（）</span><br><span class="line">5. 操作：索引、切片</span><br><span class="line">6. 运算</span><br><span class="line">数组与标量之间的运算作用于数组中每一个元素。</span><br><span class="line">一元函数运算，二元函数运算</span><br><span class="line"></span><br><span class="line"># 单元2：NumPy数据存取与函数 #</span><br><span class="line">## 数据的csv文件存取 ##</span><br><span class="line">csv文件：逗号分隔值文件。只能有效存储一维和二维数据。</span><br><span class="line">**将ndarray保存为csv：**</span><br><span class="line">np.savetxt(frame,array,fmt=&apos;%.18e&apos;,delimiter=None)</span><br><span class="line">frame:文件、字符串或产生器；</span><br><span class="line">array:存入文件的数组；</span><br><span class="line">fmt:写入文件的格式；</span><br><span class="line">delimiter：分割字符串，默认是空格；</span><br><span class="line">**将csv写入ndarray：**</span><br><span class="line">np.loadtxt(frame,dtype=np.float,delimiter=None,unpack=False)</span><br><span class="line">unpack:默认False，如为True,读入属性将分别写入不同变量；</span><br><span class="line">## 多维数据的存取 ##</span><br><span class="line">**生成文件：**</span><br><span class="line">a.tofile(frame,sep=&apos;&apos;,format=&apos;%s&apos;)</span><br><span class="line">sep:数据分割字符串，如为空，则生成一个二进制文件，而不是文本文件；</span><br><span class="line">format:写入数据的格式；</span><br><span class="line">**还原数据：**</span><br><span class="line">np.fromfile(frame,dtype=float,count=-1,sep=&apos;&apos;)</span><br><span class="line">count:读入元素个数，-1表示读入整个文件;</span><br><span class="line">**NumPy的便捷文件存取：**</span><br><span class="line">np.save(fname,array)或np.savez(fname,array)</span><br><span class="line">frame:文件名，以.npy为扩展名，压缩扩展名为.npz；</span><br><span class="line">np.load(fname)</span><br><span class="line">## NumPy的随机数函数 ##</span><br><span class="line">random子库中的的随机数基本函数：rand/randn/randint/seed;</span><br><span class="line">random子库中的的随机数高级函数：shuffle/permutation/choice;</span><br><span class="line">带有分布的高级函数：uniform/normal/poisson;</span><br><span class="line">## NumPy的统计函数 ##</span><br><span class="line">常用统计函数：sum/mean/average/std/var;</span><br><span class="line">其他统计函数：min/max/argmin/argmax/unravel_index/ptp/median;</span><br><span class="line">## NumPy的梯度函数 ##</span><br><span class="line">np.gradient(f):计算数组f中元素的梯度，当f为多维时，返回每个维度梯度，梯度，即斜率；</span><br><span class="line"></span><br><span class="line"># 单元3：实例：图像的手绘效果 #</span><br><span class="line">## 图像的数组表示 ##</span><br><span class="line">RGB色彩模式，每个通道0-255。</span><br><span class="line">PIL,Python Image Library,一个具有强大图像处理能力的第三方库。</span><br><span class="line">from PIL import Image:Image是PIL库中代表一个图像的类（对象）</span><br><span class="line">图像是一个由像素组成的二维矩阵，每个元素是一个RGB值。</span><br><span class="line">## 图像的变换 ##</span><br><span class="line">读入图像，修改RGB值，修改后保存为新的图像。</span><br><span class="line">## 图像手绘效果实例 ##</span><br><span class="line">特征：黑白灰色；边界线条较重；相同或相近颜色趋于白色；略有光源效果；</span><br></pre></td></tr></table></figure>
<p>  from PIL import Image<br>  import numpy as np</p>
<p>  a = np.asarray(Image.open(‘./beijing.jpg’).convert(‘L’)).astype(‘float’)</p>
<p>  depth = 10.                      # (0-100)<br>  grad = np.gradient(a)             #取图像灰度的梯度值<br>  grad_x, grad_y = grad               #分别取横纵图像梯度值<br>  grad_x = grad_x<em>depth/100.<br>  grad_y = grad_y</em>depth/100.<br>  A = np.sqrt(grad_x<strong>2 + grad_y</strong>2 + 1.)<br>  uni_x = grad_x/A<br>  uni_y = grad_y/A<br>  uni_z = 1./A</p>
<p>  vec_el = np.pi/2.2                   # 光源的俯视角度，弧度值<br>  vec_az = np.pi/4.                    # 光源的方位角度，弧度值<br>  dx = np.cos(vec_el)<em>np.cos(vec_az)   #光源对x 轴的影响<br>  dy = np.cos(vec_el)</em>np.sin(vec_az)   #光源对y 轴的影响<br>  dz = np.sin(vec_el)              #光源对z 轴的影响</p>
<p>  b = 255<em>(dx</em>uni_x + dy<em>uni_y + dz</em>uni_z)     #光源归一化<br>  b = b.clip(0,255)</p>
<p>  im = Image.fromarray(b.astype(‘uint8’))  #重构图像<br>  im.save(‘./beijingHD.jpg’)</p>
<pre><code></code></pre></li>
</ul>
<p>以上。</p>
<p><strong><em>注</em></strong>：转载文章请注明出处，谢谢~</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/11/">&lt;i class=&quot;fa fa-angle-left&quot;&gt;&lt;&#x2F;i&gt;</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/18/">18</a><a class="extend next" rel="next" href="/page/13/">&lt;i class=&quot;fa fa-angle-right&quot;&gt;&lt;&#x2F;i&gt;</a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Gsynf</p>
              <p class="site-description motion-element" itemprop="description">顺风不浪，逆风不怂！形而上学，不行退学！</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">88</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">29</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Gsynf</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
